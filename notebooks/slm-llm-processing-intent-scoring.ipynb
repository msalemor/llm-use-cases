{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLM and LLM token Prompt complexity and intent detection processing\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import common\n",
    "\n",
    "client = common.get_openai_client(api_key=common.api_KEY,\n",
    "        api_version=common.api_version,\n",
    "        azure_endpoint=common.api_URI)\n",
    "\n",
    "def read_file(file:str):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read()\n",
    "        \n",
    "file_401k = read_file('data/401k.txt')\n",
    "file_benefits = read_file('data/benefits.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Ollama and Azure GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_completion(prompt:str, model='gpt4o',temperature=0.1) -> str:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "        {\n",
    "           \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "    \n",
    "def ollama_completion(prompt:str, model='llava',temperature=0.1) -> int:\n",
    "    response = ollama.chat(model=model, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': prompt,        \n",
    "    },    \n",
    "    ],options = {'temperature': temperature})\n",
    "    \n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine intent and prompt complexity and process prompt on depending on basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_complexity(prompt:str):\n",
    "    template =\"\"\"system:\n",
    "You are an assistant that can score the complexity of a user's question or statement. A score can be from 0 to 10, where 0 is the least complex and 10 is the most complex.\n",
    "\n",
    "user:\n",
    "Score the following question or statement from 0 to 10:\n",
    "\n",
    "<PROMPT>\n",
    "\n",
    "Respond with the score only.\n",
    "\"\"\"\n",
    "    res = ollama_completion(template.replace('<PROMPT>', prompt))\n",
    "    # is res a number?\n",
    "    try:\n",
    "        return int(res)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def intent_detection(prompt:str):\n",
    "    template =\"\"\"system:\n",
    "You are an assistant that can determine intent from the following list of intents:\n",
    "\n",
    "401k: a user asks a 401k.\n",
    "benefits: a user asks a company benefits.\n",
    "weather: a user asks a questions about the weather.\n",
    "other: a user asks a question about anything else.\n",
    "\n",
    "user:\n",
    "<PROMPT>\n",
    "\n",
    "Respond with the intent word only unless it is the weather intent then respond with the intent and the location. For example: weather, New York.\n",
    "\"\"\"\n",
    "\n",
    "    return ollama_completion(template.replace('<PROMPT>', prompt))\n",
    "\n",
    "def process_for_complexity(prompt: str):\n",
    "    score = determine_complexity(prompt)\n",
    "    print(\"Score:\",score)\n",
    "    if score > 5:\n",
    "        # GPT processing\n",
    "        print(\"GPT processing\")\n",
    "        print(gpt_completion(prompt))\n",
    "    else:\n",
    "        # Ollama processing\n",
    "        print(\"Ollama processing\")\n",
    "        print(ollama_completion(prompt))\n",
    "\n",
    "\n",
    "def process_for_intent(prompt: str):\n",
    "    intent = intent_detection(prompt).strip()\n",
    "    print(\"Intent:\",intent)\n",
    "    if intent == 'weather':\n",
    "        location = intent.split(',')[1].strip()\n",
    "        print(f\"Intent is weather for {location}. You need a weather service.\")\n",
    "    elif intent == '401k':\n",
    "        print(\"GPT processing\")\n",
    "        print(gpt_completion(f\"{prompt}\\nContent:\\nfile_401k\\nRespond in one senetence. Use only the provided content.\"))\n",
    "    elif intent == 'benefits':\n",
    "        print(\"Ollama processing\")\n",
    "        print(ollama_completion(f\"{prompt}\\nContent:\\nfile_benefits\\nRespond in one sentence. Use only the provided content.\"))\n",
    "    else:\n",
    "        print(\"Ollama processing\")\n",
    "        print(ollama_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_for_intent(\"What is the speed of light?\")\n",
    "process_for_intent(\"What is a 401k account?\")\n",
    "process_for_intent(\"What are some company benefits?\")\n",
    "process_for_intent(\"What is the weather in London?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_for_complexity(\"What is the speed of light?\")\n",
    "process_for_complexity(\"\"\"Who was the most decorated (maximum medals) individual athlete in the Olympic games that were held at Sydney? Take a step-by-step approach in your response, cite sources and give reasoning before sharing final answer in the below format: ANSWER is: <name>\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
