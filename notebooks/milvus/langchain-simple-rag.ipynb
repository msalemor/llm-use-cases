{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milvus demo\n",
    "\n",
    "## References\n",
    "\n",
    "Source:\n",
    "- https://milvus.io/docs/quickstart.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymilvus import MilvusClient, model\n",
    "from openai import AsyncAzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "ENDPOINT = os.getenv(\"ENDPOINT\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "API_VERSION = os.getenv(\"API_VERSION\") or '2024-02-15-preview'\n",
    "CHAT_MODEL = os.getenv(\"CHAT_MODEL\")\n",
    "EMB_MODEL = os.getenv(\"EMB_MODEL\")\n",
    "\n",
    "client = MilvusClient(\"milvus_demo_oai.db\")\n",
    "oclient = AsyncAzureOpenAI(azure_endpoint=ENDPOINT,api_key=API_KEY,api_version=API_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def embed(text:str,model:str):\n",
    "    res = await oclient.embeddings.create(\n",
    "        input = [text], \n",
    "        model=model)\n",
    "    return res.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(messages:list,model:str='gpt-4o'):\n",
    "    completion = await oclient.chat.completions.create(\n",
    "    model=model,  # e.g. gpt-35-instant\n",
    "    messages=messages,    \n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_DIM = 1536\n",
    "if client.has_collection(collection_name=\"demo_collection\"):\n",
    "    client.drop_collection(collection_name=\"demo_collection\")\n",
    "client.create_collection(\n",
    "    collection_name=\"demo_collection\",\n",
    "    dimension=ADA_DIM,  # The vectors we will use in this demo has 768 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Artificial intelligence was founded as an academic discipline in 1956.\",\n",
    "    \"Alan Turing was the first person to conduct substantial research in AI.\",\n",
    "    \"Born in Maida Vale, London, Turing was raised in southern England.\",\n",
    "]\n",
    "\n",
    "vectors = [await embed(doc,EMB_MODEL) for doc in docs]\n",
    "# The output vector has 768 dimensions, matching the collection that we just created.\n",
    "print(\"Dim:\", len(vectors[0]))  # Dim: 768 (768,)\n",
    "\n",
    "# # Each entity has id, vector representation, raw text, and a subject label that we use\n",
    "# # to demo metadata filtering later.\n",
    "data = [\n",
    "     {\"id\": i, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"history\", \"url\": \"http://example.com/\" + str(i)}\n",
    "     for i in range(len(vectors))\n",
    "]\n",
    "\n",
    "print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.insert(collection_name=\"demo_collection\", data=data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question  = \"Who is Alan Turing?\"\n",
    "query_vector = await embed(question,EMB_MODEL)\n",
    "# If you don't have the embedding function you can use a fake vector to finish the demo:\n",
    "# query_vectors = [ [ random.uniform(-1, 1) for _ in range(768) ] ]\n",
    "\n",
    "res = client.search(\n",
    "    collection_name=\"demo_collection\",  # target collection\n",
    "    data=[query_vector],  # query vectors\n",
    "    limit=2,  # number of returned entities\n",
    "    output_fields=[\"text\", \"subject\",\"url\"],  # specifies fields to be returned\n",
    ")\n",
    "first_item = res[0][0]['entity']['text']\n",
    "print(first_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",      \n",
    "     \"content\": \"You are a chatbot.\"},\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": question+\"\\n\"+first_item+\"\\n\"+\"Use only the provided information to answer the question.\"},\n",
    "]\n",
    "print(await chat(messages))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
